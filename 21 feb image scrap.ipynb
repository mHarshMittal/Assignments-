{
 "cells": [
  {
   "cell_type": "raw",
   "id": "62dc81ac-bbdd-48e1-952f-21a2b61aaf38",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web Scraping is the process of extracting data from websites. It involves fetching the web pages and parsing the content to obtain specific information.\n",
    "\n",
    "Why It Is Used:\n",
    "\n",
    "Data Collection: To gather large amounts of data from the web efficiently.\n",
    "Competitive Analysis: To collect data on competitorsâ€™ pricing, products, and reviews.\n",
    "Content Aggregation: To compile information from multiple sources into a single platform.\n",
    "Three Areas Where Web Scraping Is Used:\n",
    "\n",
    "E-commerce: To collect product prices, reviews, and availability from various online retailers.\n",
    "Job Market: To gather job postings and company information from job boards and company websites.\n",
    "News and Media: To aggregate news articles, headlines, and other media content from different news websites.\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "Different Methods for Web Scraping:\n",
    "\n",
    "HTML Parsing: Extracting data from HTML pages using libraries like Beautiful Soup or lxml.\n",
    "Web Scraping Frameworks: Using tools like Scrapy or Selenium to automate the scraping process.\n",
    "API Access: Accessing data directly through APIs provided by websites, where available.\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It provides tools to navigate and search the parse tree, making it easier to extract data from web pages.\n",
    "\n",
    "Why It Is Used:\n",
    "\n",
    "Ease of Use: Simplifies the process of extracting data from HTML documents.\n",
    "Parsing Flexibility: Handles poorly-formed HTML and provides methods to traverse and search the document tree.\n",
    "Integration: Often used in combination with other libraries like requests to fetch and parse web content.\n",
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "Flask is used in a web scraping project to:\n",
    "\n",
    "Provide a Web Interface: Create a web-based interface to interact with the scraping tool, configure scraping parameters, and display results.\n",
    "API Creation: Serve as a lightweight API for triggering the scraping process and retrieving results.\n",
    "Integration: Combine web scraping functionality with a web application, allowing users to initiate and monitor scraping tasks via a browser.\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Common AWS Services Used in a Web Scraping Project:\n",
    "\n",
    "Amazon EC2 (Elastic Compute Cloud):\n",
    "\n",
    "Use: Provides virtual servers to run the web scraping scripts and manage the scraping tasks.\n",
    "Amazon S3 (Simple Storage Service):\n",
    "\n",
    "Use: Stores the scraped data, logs, and any files generated during the scraping process.\n",
    "AWS Lambda:\n",
    "\n",
    "Use: Executes code in response to events, which can be useful for running scraping tasks on a schedule or in response to triggers without managing servers.\n",
    "Amazon RDS (Relational Database Service) or DynamoDB:\n",
    "\n",
    "Use: Stores structured data obtained from scraping in a database for easy querying and analysis.\n",
    "Amazon CloudWatch:\n",
    "\n",
    "Use: Monitors and logs the performance and health of the scraping processes, and can trigger alerts or automated actions based on metrics.\n",
    "AWS IAM (Identity and Access Management):\n",
    "\n",
    "Use: Manages permissions and access controls for the AWS resources used in the web scraping project.\n",
    "These AWS services collectively support the infrastructure needed for running, storing, and managing web scraping tasks and their results.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd82db-ad25-449b-ba4a-c60a9b07c7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
